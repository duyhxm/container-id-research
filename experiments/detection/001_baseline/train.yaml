# Experiment 001: Detection Baseline
# Module: Detection
# Description: YOLOv11s baseline training

detection:
  # Experiment configuration
  experiment_name: detection_exp001_yolo11s_baseline  # Experiment name for output directory (optional, defaults to wandb.name)
  data_yaml: data/processed/detection/data.yaml  # Path to dataset configuration file
  
  # Model configuration
  model:
    architecture: yolo11s  # YOLOv11-Small (~45 MB, optimal for research)
    pretrained: true
    resume_from: null  # null = train from scratch, or path to checkpoint (e.g., "artifacts/.../weights/last.pt")
    
  # Training hyperparameters (Research-grade configuration)
  training:
    epochs: 150  # Increased for better convergence (from 100)
    batch_size: 32  # Optimized for T4 x2 GPU (from 16)
    optimizer: AdamW
    learning_rate: 0.001  # Base LR for batch_size=32
    weight_decay: 0.0005
    warmup_epochs: 5  # Increased for larger batch (from 3)
    
    # Learning rate schedule
    lr_scheduler: cosine  # Smooth decay for research training
    
    # Early stopping
    patience: 30  # Increased patience for research (from 20)
    
    # Advanced optimizer settings (previously hardcoded)
    lrf: 0.01  # Final learning rate factor (lr0 * lrf)
    momentum: 0.937  # SGD momentum (used if optimizer=SGD)
    warmup_momentum: 0.8  # Momentum during warmup
    warmup_bias_lr: 0.1  # Bias learning rate during warmup
    
    # Image size (previously hardcoded)
    imgsz: 640  # Input image size for training
    
  # Augmentation (YOLO built-in)
  augmentation:
    hsv_h: 0.015
    hsv_s: 0.7
    hsv_v: 0.4
    degrees: 10.0
    translate: 0.1
    scale: 0.5
    shear: 10.0  # Enable shear for angled perspective (87% of dataset)
    perspective: 0.0
    flipud: 0.0
    fliplr: 0.5  # OK for door detection (symmetric)
    mosaic: 1.0
    mixup: 0.0
    copy_paste: 0.0
    
  # Experiment tracking
  wandb:
    project: container-door-detection
    entity: duyhxm
    name: detection_exp001_yolo11s_baseline
    tags:
      - module1
      - detection
      - yolo11s
      - research
      - t4x2

# Hardware configuration (Specific to this experiment run)
hardware:
  # Device configuration
  device: cuda  # Options: cuda, cpu, mps (for Mac M1/M2)
  
  # Multi-GPU training (Kaggle T4 x2 configuration)
  multi_gpu: true  # Enable for Kaggle T4 x2
  gpu_ids: [0, 1]  # Use both T4 GPUs
  
  # Performance
  num_workers: 8  # Increased for dual GPU (from 4)
  pin_memory: true
  mixed_precision: true  # AMP for faster training

# Output configuration (Previously hardcoded)
output:
  # Base directory for all outputs
  base_dir: artifacts/detection  # Base directory for detection module outputs
  
  # Subdirectory name for training outputs
  train_dir: train  # Training outputs: {base_dir}/{experiment_name}/{train_dir}/
  
  # Checkpoint saving
  save_period: -1  # Save checkpoint every N epochs (-1 = only final epoch, best.pt + last.pt)
  
  # Output files
  save_plots: true   # Save training plots (loss curves, etc.)
  save_json: true    # Save metrics in JSON format
  verbose: true      # Verbose logging during training

