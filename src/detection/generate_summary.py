"""
Generate Training Summary Report

Creates a Markdown summary of training results for easy review.

Note:
    This module uses both logging and print statements:
    - logging: For debugging and error tracking
    - print: For user-facing CLI output (summary preview)
"""

import argparse
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict


def load_metadata(weights_dir: Path) -> Dict[str, Any]:
    """
    Load metadata.json file.

    Args:
        weights_dir: Path to weights directory

    Returns:
        Metadata dictionary

    Raises:
        FileNotFoundError: If metadata.json doesn't exist
    """
    metadata_path = weights_dir / "metadata.json"

    if not metadata_path.exists():
        raise FileNotFoundError(f"Metadata not found: {metadata_path}")

    with open(metadata_path, "r") as f:
        return json.load(f)


def generate_summary_markdown(metadata: Dict[str, Any], experiment_name: str) -> str:
    """
    Generate Markdown summary report.

    Args:
        metadata: Metadata dictionary
        experiment_name: Experiment name

    Returns:
        Markdown formatted string
    """
    val_metrics = metadata["final_metrics"]["validation"]
    hyperparams = metadata["hyperparameters"]

    summary = f"""# Training Summary: {experiment_name}

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Model:** {metadata['model_architecture']}  
**Trained:** {metadata['trained_on']}

---

## Final Metrics

### Validation Set

| Metric | Value |
|--------|-------|
| mAP@50 | {val_metrics['mAP50']:.4f} |
| mAP@50-95 | {val_metrics['mAP50_95']:.4f} |
| Precision | {val_metrics['precision']:.4f} |
| Recall | {val_metrics['recall']:.4f} |

---

## Hyperparameters

### Model
- Architecture: `{hyperparams['model']['architecture']}`
- Pretrained: `{hyperparams['model']['pretrained']}`

### Training
- Epochs: `{hyperparams['training']['epochs']}`
- Batch Size: `{hyperparams['training']['batch_size']}`
- Optimizer: `{hyperparams['training']['optimizer']}`
- Learning Rate: `{hyperparams['training']['learning_rate']}`
- Weight Decay: `{hyperparams['training']['weight_decay']}`
- LR Scheduler: `{hyperparams['training']['lr_scheduler']}`
- Early Stopping Patience: `{hyperparams['training']['patience']}`

### Augmentation
- HSV-H: `{hyperparams['augmentation']['hsv_h']}`
- HSV-S: `{hyperparams['augmentation']['hsv_s']}`
- HSV-V: `{hyperparams['augmentation']['hsv_v']}`
- Rotation: `±{hyperparams['augmentation']['degrees']}°`
- Translation: `{hyperparams['augmentation']['translate']}`
- Scale: `{hyperparams['augmentation']['scale']}`
- Shear: `{hyperparams['augmentation']['shear']}`
- Horizontal Flip: `{hyperparams['augmentation']['fliplr']}`
- Mosaic: `{hyperparams['augmentation']['mosaic']}`

---

## Model Files

- Best Checkpoint: `{metadata['model_files']['best_checkpoint']}`
- Last Checkpoint: `{metadata['model_files']['last_checkpoint']}`
- Results CSV: `{metadata['model_files']['results_csv']}`

---

## Next Steps

1. **Evaluate on Test Set:**
   ```bash
   python src/detection/inference.py \\
       --weights weights/detection/train/weights/best.pt \\
       --source data/processed/detection/images/test
   ```

2. **Run Inference on New Images:**
   ```bash
   yolo predict model=weights/detection/train/weights/best.pt source=path/to/images
   ```

3. **Version with DVC:**
   ```bash
   dvc add weights/detection/train/weights/best.pt
   dvc push
   ```

4. **Sync to Local Machine:**
   ```bash
   git pull
   dvc pull
   ```

---

**Generated by:** Container ID Extraction Training Pipeline  
**Project:** SOWATCO Container ID Research
"""

    return summary


def main():
    """Main entry point."""
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
    )

    parser = argparse.ArgumentParser(
        description="Generate training summary",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument("--experiment", type=str, required=True, help="Experiment name")
    parser.add_argument(
        "--weights-dir",
        type=str,
        default="weights/detection",
        help="Path to weights directory",
    )
    parser.add_argument(
        "--output", type=str, required=True, help="Output Markdown file path"
    )

    args = parser.parse_args()

    try:
        # Load metadata
        metadata = load_metadata(Path(args.weights_dir))

        # Generate summary
        summary = generate_summary_markdown(metadata, args.experiment)

        # Save to file
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(summary)

        logging.info(f"Summary generated: {output_path}")
        print(f"✓ Summary generated: {output_path}")
        print(f"\nPreview:\n")
        print(summary[:500] + "...")

    except Exception as e:
        logging.error(f"Failed to generate summary: {e}")
        raise


if __name__ == "__main__":
    main()
