# Detection Module Configuration
# Module 1: Container Door Detection
#
# This file contains all tunable parameters for the detection module:
# - Inference pipeline configuration
# - Training hyperparameters
# - Model architecture settings
# - Experiment tracking configuration

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
model:
  # Model architecture
  # Options: "yolo11n", "yolo11s", "yolo11m", "yolo11l", "yolo11x"
  architecture: yolo11s
  
  # Whether to use pretrained weights (from COCO)
  pretrained: true
  
  # Path to resume training from checkpoint
  # null = train from scratch, or path to checkpoint (e.g., "artifacts/.../weights/last.pt")
  resume_from: null
  
  # Path to model weights file for inference (relative to project root or absolute path)
  # Default: weights/detection/best.pt
  # Can be overridden when initializing DetectionProcessor
  path: "weights/detection/best.pt"

# ============================================================================
# TRAINING CONFIGURATION
# ============================================================================
training:
  # Number of training epochs
  epochs: 150
  
  # Batch size (adjust based on GPU memory)
  # T4 x2: 32, T4 x1: 16, P100: 32
  batch_size: 32
  
  # Optimizer
  optimizer: AdamW
  
  # Learning rate
  learning_rate: 0.001
  
  # Weight decay for regularization
  weight_decay: 0.0005
  
  # Warmup epochs (gradual LR increase at start)
  warmup_epochs: 5
  
  # Learning rate scheduler
  # Options: "cosine", "linear", "constant"
  lr_scheduler: cosine
  
  # Early stopping patience (epochs without improvement)
  patience: 30

# ============================================================================
# AUGMENTATION CONFIGURATION
# ============================================================================
augmentation:
  # HSV color space augmentation
  hsv_h: 0.015  # Hue shift
  hsv_s: 0.7    # Saturation variation
  hsv_v: 0.4    # Value/brightness variation
  
  # Geometric transformations
  degrees: 10.0      # Rotation ±10°
  translate: 0.1     # Translation 10%
  scale: 0.5         # Scale factor
  shear: 10.0        # Shear ±10° (important for angled perspective)
  perspective: 0.0   # Perspective warp (disabled)
  
  # Flip operations
  flipud: 0.0  # Vertical flip probability (0 = disabled, containers always upright)
  fliplr: 0.5  # Horizontal flip probability (50%, containers can face either direction)
  
  # Advanced augmentations
  mosaic: 1.0      # Mosaic augmentation probability (100%, always enabled)
  mixup: 0.0       # Mixup augmentation probability
  copy_paste: 0.0  # Copy-paste augmentation probability

# ============================================================================
# VALIDATION CONFIGURATION
# ============================================================================
validation:
  # Confidence threshold for validation/evaluation (0.0-1.0)
  conf_threshold: 0.25
  
  # IoU threshold for Non-Maximum Suppression (NMS) (0.0-1.0)
  iou_threshold: 0.45

# ============================================================================
# INFERENCE CONFIGURATION
# ============================================================================
inference:
  # Confidence threshold for detection (0.0-1.0)
  # Only detections with confidence >= this value will be returned
  # Lower values = more detections (higher recall, lower precision)
  # Higher values = fewer detections (lower recall, higher precision)
  # Default: 0.25 (matches YOLO validation default, good for demo/testing)
  # Production: 0.5-0.8 (higher precision, fewer false positives)
  conf_threshold: 0.25
  
  # IoU threshold for Non-Maximum Suppression (NMS) (0.0-1.0)
  # Detections with IoU > this value will be suppressed (only highest confidence kept)
  # Lower values = more aggressive suppression (fewer overlapping boxes)
  # Higher values = less suppression (more overlapping boxes allowed)
  iou_threshold: 0.45
  
  # Maximum number of detections to return
  # Set to -1 to return all detections above conf_threshold
  # Typically only 1 container door per image, but can be increased for batch processing
  max_detections: 1
  
  # Input image size for model inference
  # YOLOv11 standard sizes: 320, 640, 1280
  # Larger = better accuracy but slower inference
  # Smaller = faster inference but may miss small objects
  image_size: 640
  
  # Device for inference: "auto", "cpu", "cuda", "mps" (Apple Silicon)
  # "auto" will automatically select best available device
  device: "auto"
  
  # Verbose logging during inference
  # Set to true for detailed prediction logs
  verbose: false

# ============================================================================
# OUTPUT CONFIGURATION
# ============================================================================
output:
  # Include original image shape in output (required for Module 2 geometric validation)
  include_original_shape: true
  
  # Include class_id in detection results
  include_class_id: true
  
  # Sort detections by confidence (highest first)
  sort_by_confidence: true

# ============================================================================
# WANDB (EXPERIMENT TRACKING) CONFIGURATION
# ============================================================================
wandb:
  # WandB project name
  project: container-id-research
  
  # WandB entity (username or team name)
  # null = use logged-in user
  entity: null
  
  # Experiment name (will be overridden by --experiment argument if provided)
  name: detection_exp001_yolo11s_baseline
  
  # Tags for experiment organization
  tags:
    - module1
    - detection
    - yolo11s

# ============================================================================
# HARDWARE CONFIGURATION
# ============================================================================
hardware:
  # Device configuration
  # Options: "cuda", "cpu", "mps" (for Mac M1/M2)
  device: cuda
  
  # Multi-GPU training
  # Set to true to use all available GPUs
  multi_gpu: false
  
  # GPU IDs to use (if multi_gpu is true)
  # Example: [0, 1] for first two GPUs
  gpu_ids: [0]
  
  # Data loading performance
  num_workers: 4  # Number of data loading workers
  pin_memory: true  # Pin memory for faster GPU transfer
  
  # Mixed precision training (AMP)
  # Reduces memory usage and speeds up training
  mixed_precision: true

