# Container ID Extraction Research / NghiÃªn cá»©u TrÃ­ch xuáº¥t MÃ£ sá»‘ Container

[![Python Version](https://img.shields.io/badge/python-3.13-blue.svg)](https://www.python.org/downloads/)
[![DVC](https://img.shields.io/badge/DVC-Enabled-brightgreen.svg)](https://dvc.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-In%20Development-yellow.svg)]()

**English** | [Tiáº¿ng Viá»‡t](#tiáº¿ng-viá»‡t)

---

## English

### Overview

This research project develops an end-to-end computer vision system for **automated container ID extraction** from images of **container doors**. The system is designed for SOWATCO company to streamline container identification in logistics operations.

In real-world deployment scenarios, users upload various images to the system. Before extracting container IDs, we must first detect and classify whether images contain container doors, assess image quality, localize the ID region, correct perspective distortion, and finally perform text extraction.

The project outputs trained models optimized for production deployment in a separate backend service.

### System Architecture

The solution implements a **5-stage modular pipeline**:

```mermaid
graph LR
    A[Input Image] --> B[Module 1: Door Detection]
    B --> C[Module 2: Quality Assessment]
    C --> D[Module 3: ID Localization]
    D --> E[Module 4: Perspective Correction]
    E --> F[Module 5: OCR Extraction]
    F --> G[Container ID Output]
```

#### Module Descriptions

1. **Module 1: Container Door Detection**
   - **Purpose**: Detect and classify container door objects in images
   - **Technology**: YOLOv11-Nano/Small
   - **Input**: Raw image
   - **Output**: Bounding box coordinates of container door

2. **Module 2: Image Quality Assessment**
   - **Purpose**: Evaluate image quality (blur, lighting, size)
   - **Technology**: Custom quality metrics / Lightweight classifier
   - **Input**: Cropped container door image
   - **Output**: Quality score and pass/fail decision

3. **Module 3: Container ID Localization**
   - **Purpose**: Predict 4-point polygon enclosing the container ID region
   - **Technology**: YOLOv11-Pose
   - **Input**: Container door image
   - **Output**: 4 keypoint coordinates (top-left, top-right, bottom-right, bottom-left)

4. **Module 4: Perspective Correction**
   - **Purpose**: Apply perspective transform to straighten the ID region
   - **Technology**: OpenCV perspective warp + quality assessment
   - **Input**: 4 keypoints from Module 3
   - **Output**: Rectified ID region image

5. **Module 5: OCR Extraction**
   - **Purpose**: Extract container ID text from rectified image
   - **Technology**: OCR engine (PaddleOCR / EasyOCR / Custom)
   - **Input**: Rectified ID image
   - **Output**: Container ID string (validated format)

### Technology Stack

- **Language**: Python 3.13
- **Deep Learning**: YOLOv11 (Ultralytics), PyTorch
- **Data Versioning**: DVC with Google Drive backend
- **Experiment Tracking**: Weights & Biases (wandb)
- **Dependency Management**: Poetry
- **Computer Vision**: OpenCV, Albumentations
- **Data Analysis**: Pandas, NumPy, Matplotlib, Seaborn

---

## Table of Contents

- [Overview](#overview)
- [System Architecture](#system-architecture)
- [Project Structure](#project-structure)
- [Installation & Setup](#installation--setup)
- [Data Management](#data-management)
- [Usage](#usage)
  - [Data Preparation](#data-preparation)
  - [Training Individual Modules](#training-individual-modules)
  - [Running Full Pipeline](#running-full-pipeline)
  - [Notebooks](#notebooks)
- [Experiment Tracking](#experiment-tracking)
- [Model Artifacts](#model-artifacts)
- [Development Guidelines](#development-guidelines)
- [Documentation](#documentation)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License & Acknowledgments](#license--acknowledgments)

---

## Project Structure

```
container-id-research/
â”œâ”€â”€ data/                          # Data directory (managed by DVC)
â”‚   â”œâ”€â”€ raw/                       # Raw images (831 images) & annotations
â”‚   â”œâ”€â”€ annotations/               # COCO format annotations
â”‚   â”œâ”€â”€ interim/                   # Intermediate data (stratified splits)
â”‚   â””â”€â”€ processed/                 # YOLO format datasets per module
â”‚
â”œâ”€â”€ src/                           # Source code (functional organization)
â”‚   â”œâ”€â”€ data/                      # Data processing & preparation
â”‚   â”œâ”€â”€ detection/                 # Module 1: Door detection
â”‚   â”œâ”€â”€ quality/                   # Module 2: Quality assessment
â”‚   â”œâ”€â”€ localization/              # Module 3: ID localization
â”‚   â”œâ”€â”€ alignment/                 # Module 4: Perspective correction
â”‚   â”œâ”€â”€ ocr/                       # Module 5: OCR extraction
â”‚   â”œâ”€â”€ pipeline/                  # End-to-end orchestration
â”‚   â””â”€â”€ utils/                     # Shared utilities
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks for EDA
â”œâ”€â”€ experiments/                   # Experiment results & wandb logs
â”œâ”€â”€ weights/                       # Trained model weights
â”œâ”€â”€ documentation/                 # Comprehensive documentation
â”‚   â”œâ”€â”€ general/                   # Architecture & guidelines
â”‚   â”œâ”€â”€ data-labeling/             # Annotation guidelines
â”‚   â””â”€â”€ modules/                   # Per-module technical specs
â”‚
â”œâ”€â”€ scripts/                       # Utility scripts
â”œâ”€â”€ tests/                         # Unit & integration tests
â”œâ”€â”€ dvc.yaml                       # DVC pipeline definition
â”œâ”€â”€ params.yaml                    # Centralized parameters
â””â”€â”€ pyproject.toml                 # Poetry dependencies
```

### Directory Explanations

- **`data/`**: All datasets managed by DVC. `raw/` contains original images, `interim/` holds stratified train/val/test splits, `processed/` contains YOLO-formatted data per module.
- **`src/`**: Source code organized by functionality. Each module is self-contained with training, inference, and utilities.
- **`notebooks/`**: Exploratory Data Analysis and result visualization notebooks.
- **`experiments/`**: Stores experiment configurations, results, and wandb logs (gitignored).
- **`weights/`**: Model checkpoints organized by module.
- **`documentation/`**: In-depth documentation including data labeling guidelines, methodology papers, and technical specifications.
- **`scripts/`**: Automation scripts for setup, data download, and pipeline execution.

---

## Installation & Setup

### Prerequisites

- **Python 3.13** (required)
- **Poetry** (dependency manager)
- **Git** (version control)
- **DVC** (data version control)
- **Google Drive account** (for data access)

### Step-by-Step Installation

1. **Clone the repository**

```bash
git clone <repository-url>
cd container-id-research
```

2. **Install dependencies with Poetry**

```bash
# Install Poetry if not already installed
curl -sSL https://install.python-poetry.org | python3 -

# Install project dependencies
poetry install
```

3. **Activate virtual environment**

```bash
poetry shell
```

4. **Setup DVC and pull data**

```bash
# Initialize DVC (if needed)
dvc remote default storage

# Pull data from Google Drive
dvc pull
```

5. **Verify installation**

```bash
# Check Python version
python --version  # Should show 3.13.x

# Verify DVC data
ls data/raw/  # Should show images
```

---

## Data Management

### Dataset Overview

- **Total Images**: 831
- **Categories**: 2 (container_door, container_id)
- **Annotations**: 989 total (500 doors, 489 IDs)
- **Format**: COCO JSON for annotations, JPEG/PNG for images
- **Storage**: Google Drive via DVC

### Data Versioning with DVC

This project uses **DVC (Data Version Control)** to manage large datasets and model weights efficiently.

**Key DVC Files**:
- `data/raw.dvc`: Tracks the raw data directory
- `.dvc/config`: DVC remote configuration (Google Drive)
- `dvc.yaml`: DVC pipeline for data processing stages

**Common DVC Commands**:

```bash
# Pull latest data from remote
dvc pull

# Check data status
dvc status

# Reproduce entire pipeline
dvc repro

# Push new data to remote
dvc add data/raw
dvc push
```

### Data Stratification Methodology

The project employs **Label Powerset Stratification with Rare-Class Aggregation** to ensure balanced representation of edge cases in train/val/test splits.

**Key Features**:
- Stratification based on image attributes (lighting, angle, occlusion, surface, sharpness)
- Priority-based grouping (hard, tricky, common)
- Singleton handling with controlled augmentation
- Ratios: 70% Train, 15% Validation, 15% Test

ğŸ“š **Detailed methodology**: See [`documentation/modules/module-1-detection/data-splitting-methodology.md`](documentation/modules/module-1-detection/data-splitting-methodology.md)

---

## Usage

### Data Preparation

Run the DVC pipeline to process raw data and generate YOLO-formatted datasets:

```bash
# Execute full data pipeline
dvc repro

# Or run specific stages
dvc repro split_data
dvc repro convert_detection
dvc repro convert_localization
```

### Training Individual Modules

#### Module 1: Container Door Detection

**Local Training:**
```bash
# Train YOLOv11 detection model
python src/detection/train.py --config experiments/detection/exp001_baseline/config.yaml

# Run inference
python src/detection/inference.py --weights weights/detection/best.pt --source test_images/
```

**Kaggle Training (Recommended):**
> ğŸ“Œ For GPU-accelerated training on Kaggle (free T4/P100 GPUs), see: [**Kaggle Training Guide**](KAGGLE_TRAINING_GUIDE.md)
>
> The guide includes:
> - Direct notebook workflow (single-cell execution)
> - DVC session token setup (automatic model sync)
> - WandB integration for experiment tracking
> - Expected results: mAP@50 > 0.90, inference < 50ms

#### Module 3: Container ID Localization

```bash
# Train YOLOv11 pose model
python src/localization/train.py --config experiments/localization/exp001_baseline/config.yaml

# Run inference
python src/localization/inference.py --weights weights/localization/best.pt --source test_images/
```

### Running Full Pipeline

Execute the end-to-end pipeline on a single image or batch:

```bash
# Single image
python src/pipeline/full_pipeline.py --input path/to/image.jpg --output results/

# Batch processing
python src/pipeline/full_pipeline.py --input path/to/folder/ --output results/ --batch
```

### Notebooks

Explore data and visualize results using Jupyter notebooks:

```bash
# Launch Jupyter
jupyter notebook

# Available notebooks:
# - 01-annotated-image-eda.ipynb: Dataset exploration and statistics
# - 02-module1-detection-analysis.ipynb: Detection results analysis
# - 03-module3-localization-analysis.ipynb: Localization evaluation
# - 04-end-to-end-pipeline-demo.ipynb: Full pipeline demonstration
```

---

## Experiment Tracking

### Weights & Biases Integration

This project uses **wandb** for experiment tracking and visualization.

**Setup**:

```bash
# Login to wandb
wandb login

# Your experiments will be automatically logged
```

**Experiment Naming Convention**:

```
<module>_exp<number>_<description>

Examples:
- detection_exp001_yolo11n_baseline
- detection_exp002_yolo11s_augmented
- localization_exp001_yolo11_pose_baseline
```

**Tracked Metrics**:
- Training/validation loss curves
- mAP@50, mAP@50-95 (detection)
- OKS (Object Keypoint Similarity) for pose
- Inference time and FPS
- Model hyperparameters
- Dataset statistics

**Access Results**:
- Visit your wandb dashboard: `https://wandb.ai/<your-username>/container-id-research`
- Local results saved in `experiments/<module>/exp<number>/`

---

## Model Artifacts

### Model Storage

Trained models are stored in the `weights/` directory, organized by module:

```
weights/
â”œâ”€â”€ detection/
â”‚   â”œâ”€â”€ best.pt          # Best checkpoint based on validation mAP
â”‚   â””â”€â”€ last.pt          # Latest checkpoint
â”œâ”€â”€ localization/
â”‚   â”œâ”€â”€ best.pt
â”‚   â””â”€â”€ last.pt
â””â”€â”€ ocr/
    â””â”€â”€ best.pt
```

### Model Versioning Strategy

- **Git**: Track model metadata and configuration files
- **DVC**: Track large model weight files (`.pt` files)
- **wandb**: Track experiment history and model performance

### Exporting for Production

```bash
# Export models with metadata
python scripts/export_models.py --module detection --version v1.0

# Output: Packaged model ready for backend integration
```

### Performance Benchmarks

_(To be updated as training progresses)_

| Module          | Model        | mAP@50 | mAP@50-95 | Inference Time | Size |
| --------------- | ------------ | ------ | --------- | -------------- | ---- |
| Door Detection  | YOLOv11n     | TBD    | TBD       | TBD            | TBD  |
| ID Localization | YOLOv11-Pose | TBD    | TBD       | TBD            | TBD  |

---

## Development Guidelines

### Code Style

- **PEP 8**: Follow Python style guidelines
- **Black**: Code formatter (line length: 88)
- **isort**: Import sorting
- **Type hints**: Use type annotations where applicable

```bash
# Format code
black src/
isort src/

# Check style
flake8 src/
```

### Conventional Commits

This project follows **Unified Conventional Commits Standard (UCCS)**.

**Commit format**:
```
<type>(<scope>): <description>

[optional body]
```

**Types**:
- `feat`: New feature or capability
- `fix`: Bug fix or correction
- `refactor`: Code restructuring without behavior change
- `docs`: Documentation updates
- `style`: Code formatting (no logic change)
- `chore`: Maintenance tasks (dependencies, configs)

ğŸ“š **Full guidelines**: [`documentation/general/conventional-commit-guideline.md`](documentation/general/conventional-commit-guideline.md)

### Branch Strategy

- `main`: Production-ready code
- `develop`: Integration branch
- `feature/*`: New features
- `fix/*`: Bug fixes
- `experiment/*`: Experimental work

### Pull Request Workflow

1. Create feature branch from `develop`
2. Make changes with conventional commits
3. Write/update tests
4. Submit PR with clear description
5. Pass CI checks and code review
6. Merge to `develop`

### Testing Requirements

```bash
# Run all tests
pytest tests/

# Run specific module tests
pytest tests/test_detection.py

# Generate coverage report
pytest --cov=src tests/
```

---

## Documentation

### Available Documentation

#### General
- [Conventional Commit Guidelines](documentation/general/conventional-commit-guideline.md)
- [System Architecture](documentation/general/architecture.md) _(To be created)_

#### Data Labeling
- [Attribute Annotation Guideline](documentation/data-labeling/attribute-annotation-guideline.md)
- [Container Door Labeling Guideline](documentation/data-labeling/container-door-labeling-guideline.md)
- [Container ID Labeling Guideline](documentation/data-labeling/id-container-labeling-guideline.md)

#### Module-Specific
- **Module 1 (Detection)**:
  - [Data Splitting Methodology](documentation/modules/module-1-detection/data-splitting-methodology.md)
  - [Technical Specification: Data Splitting](documentation/modules/module-1-detection/technical-specification-data-splitting.md)
  - [Training Guide](documentation/modules/module-1-detection/training-guide.md) _(To be created)_

---

## Roadmap

### Current Status

- âœ… Data collection and annotation (831 images)
- âœ… Data labeling guidelines established
- âœ… Data stratification methodology designed
- âœ… EDA and dataset analysis complete
- ğŸŸ¡ Module 1 (Detection) - In development
- ğŸŸ¡ Module 3 (Localization) - In development

### Upcoming Milestones

- [ ] Complete Module 1 training and evaluation
- [ ] Complete Module 3 training and evaluation
- [ ] Implement Module 2 (Quality Assessment)
- [ ] Implement Module 4 (Perspective Correction)
- [ ] Implement Module 5 (OCR Extraction)
- [ ] End-to-end pipeline integration and testing
- [ ] Performance optimization and benchmarking
- [ ] Production deployment preparation
- [ ] Backend service integration

### Future Enhancements

- Real-time video processing
- Multi-container detection in single image
- Mobile deployment (TensorFlow Lite / ONNX)
- API service with FastAPI
- Continuous learning pipeline

---

## Contributing

### How to Contribute

We welcome contributions! Here's how you can help:

1. **Report Issues**: Use GitHub Issues for bug reports and feature requests
2. **Submit Pull Requests**: Follow the PR workflow outlined above
3. **Improve Documentation**: Fix typos, add examples, clarify explanations
4. **Share Ideas**: Discuss improvements in GitHub Discussions

### Contact

- **Project Lead**: duyhxm
- **Organization**: SOWATCO Company
- **Email**: _(Add if applicable)_

---

## License & Acknowledgments

### License

This project is licensed under the **MIT License**. See [LICENSE](LICENSE) file for details.

### Acknowledgments

- **SOWATCO Company** for project sponsorship and domain expertise
- **Ultralytics** for the YOLOv11 framework
- **DVC Team** for data versioning tools
- **Weights & Biases** for experiment tracking platform
- **CVAT** for annotation tools
- Open-source community for libraries: OpenCV, PyTorch, Albumentations

### References

- [YOLOv11 Documentation](https://docs.ultralytics.com/)
- [DVC Documentation](https://dvc.org/doc)
- [Weights & Biases Documentation](https://docs.wandb.ai/)
- [COCO Dataset Format](https://cocodataset.org/#format-data)

---

# Tiáº¿ng Viá»‡t

## Tá»•ng quan

Dá»± Ã¡n nghiÃªn cá»©u nÃ y phÃ¡t triá»ƒn má»™t há»‡ thá»‘ng thá»‹ giÃ¡c mÃ¡y tÃ­nh end-to-end Ä‘á»ƒ **tá»± Ä‘á»™ng trÃ­ch xuáº¥t mÃ£ sá»‘ container** tá»« hÃ¬nh áº£nh **cá»­a sau container**. Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ cho cÃ´ng ty SOWATCO nháº±m tá»‘i Æ°u hÃ³a quy trÃ¬nh nháº­n diá»‡n container trong hoáº¡t Ä‘á»™ng logistics.

Trong mÃ´i trÆ°á»ng triá»ƒn khai thá»±c táº¿, ngÆ°á»i dÃ¹ng táº£i lÃªn nhiá»u loáº¡i hÃ¬nh áº£nh khÃ¡c nhau. TrÆ°á»›c khi trÃ­ch xuáº¥t mÃ£ sá»‘ container, chÃºng ta pháº£i phÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i xem áº£nh cÃ³ chá»©a cá»­a container khÃ´ng, Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng áº£nh, Ä‘á»‹nh vá»‹ vÃ¹ng chá»©a mÃ£ sá»‘, náº¯n chá»‰nh phá»‘i cáº£nh, vÃ  cuá»‘i cÃ¹ng thá»±c hiá»‡n trÃ­ch xuáº¥t vÄƒn báº£n.

Sáº£n pháº©m Ä‘áº§u ra cá»§a dá»± Ã¡n lÃ  cÃ¡c model Ä‘Æ°á»£c huáº¥n luyá»‡n tá»‘i Æ°u Ä‘á»ƒ triá»ƒn khai trong má»™t dá»‹ch vá»¥ backend riÃªng biá»‡t.

## Kiáº¿n trÃºc Há»‡ thá»‘ng

Giáº£i phÃ¡p triá»ƒn khai **pipeline 5 giai Ä‘oáº¡n modular**:

```mermaid
graph LR
    A[áº¢nh Ä‘áº§u vÃ o] --> B[Module 1: PhÃ¡t hiá»‡n Cá»­a]
    B --> C[Module 2: ÄÃ¡nh giÃ¡ Cháº¥t lÆ°á»£ng]
    C --> D[Module 3: Äá»‹nh vá»‹ ID]
    D --> E[Module 4: Náº¯n chá»‰nh Phá»‘i cáº£nh]
    E --> F[Module 5: TrÃ­ch xuáº¥t OCR]
    F --> G[Káº¿t quáº£ MÃ£ Container]
```

### MÃ´ táº£ cÃ¡c Module

1. **Module 1: PhÃ¡t hiá»‡n Cá»­a Container**
   - **Má»¥c Ä‘Ã­ch**: PhÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i Ä‘á»‘i tÆ°á»£ng cá»­a container trong áº£nh
   - **CÃ´ng nghá»‡**: YOLOv11-Nano/Small
   - **Äáº§u vÃ o**: áº¢nh gá»‘c
   - **Äáº§u ra**: Tá»a Ä‘á»™ bounding box cá»§a cá»­a container

2. **Module 2: ÄÃ¡nh giÃ¡ Cháº¥t lÆ°á»£ng áº¢nh**
   - **Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng áº£nh (Ä‘á»™ má», Ã¡nh sÃ¡ng, kÃ­ch thÆ°á»›c)
   - **CÃ´ng nghá»‡**: Chá»‰ sá»‘ cháº¥t lÆ°á»£ng tÃ¹y chá»‰nh / Classifier nháº¹
   - **Äáº§u vÃ o**: áº¢nh cá»­a container Ä‘Ã£ crop
   - **Äáº§u ra**: Äiá»ƒm cháº¥t lÆ°á»£ng vÃ  quyáº¿t Ä‘á»‹nh pass/fail

3. **Module 3: Äá»‹nh vá»‹ MÃ£ sá»‘ Container**
   - **Má»¥c Ä‘Ã­ch**: Dá»± Ä‘oÃ¡n Ä‘a giÃ¡c 4 Ä‘iá»ƒm bao quanh vÃ¹ng chá»©a mÃ£ container
   - **CÃ´ng nghá»‡**: YOLOv11-Pose
   - **Äáº§u vÃ o**: áº¢nh cá»­a container
   - **Äáº§u ra**: 4 tá»a Ä‘á»™ keypoint (trÃªn-trÃ¡i, trÃªn-pháº£i, dÆ°á»›i-pháº£i, dÆ°á»›i-trÃ¡i)

4. **Module 4: Náº¯n chá»‰nh Phá»‘i cáº£nh**
   - **Má»¥c Ä‘Ã­ch**: Ãp dá»¥ng biáº¿n Ä‘á»•i phá»‘i cáº£nh Ä‘á»ƒ lÃ m tháº³ng vÃ¹ng ID
   - **CÃ´ng nghá»‡**: OpenCV perspective warp + Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng
   - **Äáº§u vÃ o**: 4 keypoint tá»« Module 3
   - **Äáº§u ra**: áº¢nh vÃ¹ng ID Ä‘Ã£ Ä‘Æ°á»£c náº¯n chá»‰nh

5. **Module 5: TrÃ­ch xuáº¥t OCR**
   - **Má»¥c Ä‘Ã­ch**: TrÃ­ch xuáº¥t vÄƒn báº£n mÃ£ container tá»« áº£nh Ä‘Ã£ náº¯n chá»‰nh
   - **CÃ´ng nghá»‡**: OCR engine (PaddleOCR / EasyOCR / Custom)
   - **Äáº§u vÃ o**: áº¢nh ID Ä‘Ã£ náº¯n chá»‰nh
   - **Äáº§u ra**: Chuá»—i mÃ£ container (Ä‘á»‹nh dáº¡ng Ä‘Ã£ validate)

## NgÄƒn xáº¿p CÃ´ng nghá»‡

- **NgÃ´n ngá»¯**: Python 3.13
- **Deep Learning**: YOLOv11 (Ultralytics), PyTorch
- **Quáº£n lÃ½ phiÃªn báº£n dá»¯ liá»‡u**: DVC vá»›i Google Drive backend
- **Theo dÃµi thá»±c nghiá»‡m**: Weights & Biases (wandb)
- **Quáº£n lÃ½ dependencies**: Poetry
- **Computer Vision**: OpenCV, Albumentations
- **PhÃ¢n tÃ­ch dá»¯ liá»‡u**: Pandas, NumPy, Matplotlib, Seaborn

---

## Má»¥c lá»¥c

- [Tá»•ng quan](#tá»•ng-quan)
- [Kiáº¿n trÃºc Há»‡ thá»‘ng](#kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [Cáº¥u trÃºc Dá»± Ã¡n](#cáº¥u-trÃºc-dá»±-Ã¡n)
- [CÃ i Ä‘áº·t & Thiáº¿t láº­p](#cÃ i-Ä‘áº·t--thiáº¿t-láº­p)
- [Quáº£n lÃ½ Dá»¯ liá»‡u](#quáº£n-lÃ½-dá»¯-liá»‡u)
- [Sá»­ dá»¥ng](#sá»­-dá»¥ng)
- [Theo dÃµi Thá»±c nghiá»‡m](#theo-dÃµi-thá»±c-nghiá»‡m)
- [Sáº£n pháº©m Model](#sáº£n-pháº©m-model)
- [HÆ°á»›ng dáº«n PhÃ¡t triá»ƒn](#hÆ°á»›ng-dáº«n-phÃ¡t-triá»ƒn)
- [TÃ i liá»‡u](#tÃ i-liá»‡u)
- [Lá»™ trÃ¬nh](#lá»™-trÃ¬nh)
- [ÄÃ³ng gÃ³p](#Ä‘Ã³ng-gÃ³p)
- [Giáº¥y phÃ©p & Ghi nháº­n](#giáº¥y-phÃ©p--ghi-nháº­n)

---

## Cáº¥u trÃºc Dá»± Ã¡n

```
container-id-research/
â”œâ”€â”€ data/                          # ThÆ° má»¥c dá»¯ liá»‡u (quáº£n lÃ½ bá»Ÿi DVC)
â”‚   â”œâ”€â”€ raw/                       # áº¢nh gá»‘c (831 áº£nh) & annotations
â”‚   â”œâ”€â”€ annotations/               # Annotations Ä‘á»‹nh dáº¡ng COCO
â”‚   â”œâ”€â”€ interim/                   # Dá»¯ liá»‡u trung gian (stratified splits)
â”‚   â””â”€â”€ processed/                 # Datasets Ä‘á»‹nh dáº¡ng YOLO cho tá»«ng module
â”‚
â”œâ”€â”€ src/                           # MÃ£ nguá»“n (tá»• chá»©c theo chá»©c nÄƒng)
â”‚   â”œâ”€â”€ data/                      # Xá»­ lÃ½ & chuáº©n bá»‹ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ detection/                 # Module 1: PhÃ¡t hiá»‡n cá»­a
â”‚   â”œâ”€â”€ quality/                   # Module 2: ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng
â”‚   â”œâ”€â”€ localization/              # Module 3: Äá»‹nh vá»‹ ID
â”‚   â”œâ”€â”€ alignment/                 # Module 4: Náº¯n chá»‰nh phá»‘i cáº£nh
â”‚   â”œâ”€â”€ ocr/                       # Module 5: TrÃ­ch xuáº¥t OCR
â”‚   â”œâ”€â”€ pipeline/                  # Äiá»u phá»‘i end-to-end
â”‚   â””â”€â”€ utils/                     # Tiá»‡n Ã­ch dÃ¹ng chung
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks cho EDA
â”œâ”€â”€ experiments/                   # Káº¿t quáº£ thá»±c nghiá»‡m & wandb logs
â”œâ”€â”€ weights/                       # Trá»ng sá»‘ model Ä‘Ã£ train
â”œâ”€â”€ documentation/                 # TÃ i liá»‡u toÃ n diá»‡n
â”‚   â”œâ”€â”€ general/                   # Kiáº¿n trÃºc & hÆ°á»›ng dáº«n
â”‚   â”œâ”€â”€ data-labeling/             # HÆ°á»›ng dáº«n gÃ¡n nhÃ£n
â”‚   â””â”€â”€ modules/                   # Äáº·c táº£ ká»¹ thuáº­t tá»«ng module
â”‚
â”œâ”€â”€ scripts/                       # Scripts tiá»‡n Ã­ch
â”œâ”€â”€ tests/                         # Unit & integration tests
â”œâ”€â”€ dvc.yaml                       # Äá»‹nh nghÄ©a DVC pipeline
â”œâ”€â”€ params.yaml                    # Tham sá»‘ táº­p trung
â””â”€â”€ pyproject.toml                 # Poetry dependencies
```

### Giáº£i thÃ­ch ThÆ° má»¥c

- **`data/`**: Táº¥t cáº£ datasets Ä‘Æ°á»£c quáº£n lÃ½ bá»Ÿi DVC. `raw/` chá»©a áº£nh gá»‘c, `interim/` chá»©a train/val/test splits Ä‘Ã£ phÃ¢n táº§ng, `processed/` chá»©a dá»¯ liá»‡u Ä‘á»‹nh dáº¡ng YOLO cho tá»«ng module.
- **`src/`**: MÃ£ nguá»“n Ä‘Æ°á»£c tá»• chá»©c theo chá»©c nÄƒng. Má»—i module Ä‘á»™c láº­p vá»›i training, inference vÃ  utilities.
- **`notebooks/`**: Notebooks phÃ¢n tÃ­ch dá»¯ liá»‡u khÃ¡m phÃ¡ vÃ  trá»±c quan hÃ³a káº¿t quáº£.
- **`experiments/`**: LÆ°u trá»¯ cáº¥u hÃ¬nh thá»±c nghiá»‡m, káº¿t quáº£ vÃ  wandb logs (gitignored).
- **`weights/`**: Model checkpoints Ä‘Æ°á»£c tá»• chá»©c theo module.
- **`documentation/`**: TÃ i liá»‡u chi tiáº¿t bao gá»“m hÆ°á»›ng dáº«n gÃ¡n nhÃ£n, phÆ°Æ¡ng phÃ¡p luáº­n vÃ  Ä‘áº·c táº£ ká»¹ thuáº­t.
- **`scripts/`**: Scripts tá»± Ä‘á»™ng hÃ³a cho thiáº¿t láº­p, táº£i dá»¯ liá»‡u vÃ  thá»±c thi pipeline.

---

## CÃ i Ä‘áº·t & Thiáº¿t láº­p

### YÃªu cáº§u

- **Python 3.13** (báº¯t buá»™c)
- **Poetry** (quáº£n lÃ½ dependencies)
- **Git** (version control)
- **DVC** (data version control)
- **TÃ i khoáº£n Google Drive** (Ä‘á»ƒ truy cáº­p dá»¯ liá»‡u)

### HÆ°á»›ng dáº«n CÃ i Ä‘áº·t Chi tiáº¿t

1. **Clone repository**

```bash
git clone <repository-url>
cd container-id-research
```

2. **CÃ i Ä‘áº·t dependencies vá»›i Poetry**

```bash
# CÃ i Ä‘áº·t Poetry náº¿u chÆ°a cÃ³
curl -sSL https://install.python-poetry.org | python3 -

# CÃ i Ä‘áº·t dependencies cá»§a dá»± Ã¡n
poetry install
```

3. **KÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o**

```bash
poetry shell
```

4. **Thiáº¿t láº­p DVC vÃ  táº£i dá»¯ liá»‡u**

```bash
# Khá»Ÿi táº¡o DVC (náº¿u cáº§n)
dvc remote default storage

# Táº£i dá»¯ liá»‡u tá»« Google Drive
dvc pull
```

5. **Kiá»ƒm tra cÃ i Ä‘áº·t**

```bash
# Kiá»ƒm tra phiÃªn báº£n Python
python --version  # Pháº£i hiá»ƒn thá»‹ 3.13.x

# Kiá»ƒm tra dá»¯ liá»‡u DVC
ls data/raw/  # Pháº£i hiá»ƒn thá»‹ áº£nh
```

---

## Quáº£n lÃ½ Dá»¯ liá»‡u

### Tá»•ng quan Dataset

- **Tá»•ng sá»‘ áº£nh**: 831
- **Danh má»¥c**: 2 (container_door, container_id)
- **Annotations**: 989 tá»•ng (500 cá»­a, 489 ID)
- **Äá»‹nh dáº¡ng**: COCO JSON cho annotations, JPEG/PNG cho áº£nh
- **LÆ°u trá»¯**: Google Drive qua DVC

### Quáº£n lÃ½ phiÃªn báº£n Dá»¯ liá»‡u vá»›i DVC

Dá»± Ã¡n nÃ y sá»­ dá»¥ng **DVC (Data Version Control)** Ä‘á»ƒ quáº£n lÃ½ datasets lá»›n vÃ  trá»ng sá»‘ model hiá»‡u quáº£.

**CÃ¡c file DVC quan trá»ng**:
- `data/raw.dvc`: Theo dÃµi thÆ° má»¥c dá»¯ liá»‡u gá»‘c
- `.dvc/config`: Cáº¥u hÃ¬nh DVC remote (Google Drive)
- `dvc.yaml`: DVC pipeline cho cÃ¡c giai Ä‘oáº¡n xá»­ lÃ½ dá»¯ liá»‡u

**Lá»‡nh DVC thÃ´ng dá»¥ng**:

```bash
# Táº£i dá»¯ liá»‡u má»›i nháº¥t tá»« remote
dvc pull

# Kiá»ƒm tra tráº¡ng thÃ¡i dá»¯ liá»‡u
dvc status

# TÃ¡i táº¡o toÃ n bá»™ pipeline
dvc repro

# Äáº©y dá»¯ liá»‡u má»›i lÃªn remote
dvc add data/raw
dvc push
```

### PhÆ°Æ¡ng phÃ¡p PhÃ¢n táº§ng Dá»¯ liá»‡u

Dá»± Ã¡n Ã¡p dá»¥ng **PhÃ¢n táº§ng dá»±a trÃªn Label Powerset vá»›i Gá»™p nhÃ³m Rare-Class** Ä‘á»ƒ Ä‘áº£m báº£o Ä‘áº¡i diá»‡n cÃ¢n báº±ng cÃ¡c trÆ°á»ng há»£p biÃªn trong train/val/test splits.

**Äáº·c Ä‘iá»ƒm chÃ­nh**:
- PhÃ¢n táº§ng dá»±a trÃªn thuá»™c tÃ­nh áº£nh (Ã¡nh sÃ¡ng, gÃ³c, che khuáº¥t, bá» máº·t, Ä‘á»™ nÃ©t)
- Gom nhÃ³m theo Æ°u tiÃªn (hard, tricky, common)
- Xá»­ lÃ½ singleton vá»›i augmentation cÃ³ kiá»ƒm soÃ¡t
- Tá»· lá»‡: 70% Train, 15% Validation, 15% Test

ğŸ“š **PhÆ°Æ¡ng phÃ¡p chi tiáº¿t**: Xem [`documentation/modules/module-1-detection/data-splitting-methodology.md`](documentation/modules/module-1-detection/data-splitting-methodology.md)

---

## Sá»­ dá»¥ng

### Chuáº©n bá»‹ Dá»¯ liá»‡u

Cháº¡y DVC pipeline Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u gá»‘c vÃ  táº¡o datasets Ä‘á»‹nh dáº¡ng YOLO:

```bash
# Thá»±c thi toÃ n bá»™ data pipeline
dvc repro

# Hoáº·c cháº¡y cÃ¡c giai Ä‘oáº¡n cá»¥ thá»ƒ
dvc repro split_data
dvc repro convert_detection
dvc repro convert_localization
```

### Huáº¥n luyá»‡n cÃ¡c Module RiÃªng láº»

#### Module 1: PhÃ¡t hiá»‡n Cá»­a Container

```bash
# Huáº¥n luyá»‡n YOLOv11 detection model
python src/detection/train.py --config experiments/detection/exp001_baseline/config.yaml

# Cháº¡y inference
python src/detection/inference.py --weights weights/detection/best.pt --source test_images/
```

#### Module 3: Äá»‹nh vá»‹ MÃ£ sá»‘ Container

```bash
# Huáº¥n luyá»‡n YOLOv11 pose model
python src/localization/train.py --config experiments/localization/exp001_baseline/config.yaml

# Cháº¡y inference
python src/localization/inference.py --weights weights/localization/best.pt --source test_images/
```

### Cháº¡y Pipeline Äáº§y Ä‘á»§

Thá»±c thi pipeline end-to-end trÃªn má»™t áº£nh hoáº·c batch:

```bash
# Má»™t áº£nh
python src/pipeline/full_pipeline.py --input path/to/image.jpg --output results/

# Xá»­ lÃ½ batch
python src/pipeline/full_pipeline.py --input path/to/folder/ --output results/ --batch
```

### Notebooks

KhÃ¡m phÃ¡ dá»¯ liá»‡u vÃ  trá»±c quan hÃ³a káº¿t quáº£ báº±ng Jupyter notebooks:

```bash
# Khá»Ÿi Ä‘á»™ng Jupyter
jupyter notebook

# Notebooks cÃ³ sáºµn:
# - 01-annotated-image-eda.ipynb: KhÃ¡m phÃ¡ dataset vÃ  thá»‘ng kÃª
# - 02-module1-detection-analysis.ipynb: PhÃ¢n tÃ­ch káº¿t quáº£ detection
# - 03-module3-localization-analysis.ipynb: ÄÃ¡nh giÃ¡ localization
# - 04-end-to-end-pipeline-demo.ipynb: Demo pipeline Ä‘áº§y Ä‘á»§
```

---

## Theo dÃµi Thá»±c nghiá»‡m

### TÃ­ch há»£p Weights & Biases

Dá»± Ã¡n nÃ y sá»­ dá»¥ng **wandb** Ä‘á»ƒ theo dÃµi vÃ  trá»±c quan hÃ³a thá»±c nghiá»‡m.

**Thiáº¿t láº­p**:

```bash
# ÄÄƒng nháº­p wandb
wandb login

# CÃ¡c thá»±c nghiá»‡m sáº½ tá»± Ä‘á»™ng Ä‘Æ°á»£c log
```

**Quy Æ°á»›c Äáº·t tÃªn Thá»±c nghiá»‡m**:

```
<module>_exp<sá»‘>_<mÃ´_táº£>

VÃ­ dá»¥:
- detection_exp001_yolo11n_baseline
- detection_exp002_yolo11s_augmented
- localization_exp001_yolo11_pose_baseline
```

**Chá»‰ sá»‘ Ä‘Æ°á»£c Theo dÃµi**:
- ÄÆ°á»ng cong loss training/validation
- mAP@50, mAP@50-95 (detection)
- OKS (Object Keypoint Similarity) cho pose
- Thá»i gian inference vÃ  FPS
- Hyperparameters cá»§a model
- Thá»‘ng kÃª dataset

**Truy cáº­p Káº¿t quáº£**:
- Truy cáº­p wandb dashboard: `https://wandb.ai/<tÃªn-ngÆ°á»i-dÃ¹ng>/container-id-research`
- Káº¿t quáº£ local Ä‘Æ°á»£c lÆ°u trong `experiments/<module>/exp<sá»‘>/`

---

## Sáº£n pháº©m Model

### LÆ°u trá»¯ Model

CÃ¡c model Ä‘Ã£ train Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c `weights/`, tá»• chá»©c theo module:

```
weights/
â”œâ”€â”€ detection/
â”‚   â”œâ”€â”€ best.pt          # Checkpoint tá»‘t nháº¥t dá»±a trÃªn validation mAP
â”‚   â””â”€â”€ last.pt          # Checkpoint má»›i nháº¥t
â”œâ”€â”€ localization/
â”‚   â”œâ”€â”€ best.pt
â”‚   â””â”€â”€ last.pt
â””â”€â”€ ocr/
    â””â”€â”€ best.pt
```

### Chiáº¿n lÆ°á»£c PhiÃªn báº£n Model

- **Git**: Theo dÃµi metadata vÃ  file cáº¥u hÃ¬nh model
- **DVC**: Theo dÃµi file trá»ng sá»‘ model lá»›n (`.pt` files)
- **wandb**: Theo dÃµi lá»‹ch sá»­ thá»±c nghiá»‡m vÃ  hiá»‡u nÄƒng model

### Xuáº¥t cho Production

```bash
# Xuáº¥t models vá»›i metadata
python scripts/export_models.py --module detection --version v1.0

# Output: Model Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i sáºµn sÃ ng cho tÃ­ch há»£p backend
```

### Benchmark Hiá»‡u nÄƒng

_(Sáº½ Ä‘Æ°á»£c cáº­p nháº­t khi quÃ¡ trÃ¬nh training hoÃ n thÃ nh)_

| Module        | Model        | mAP@50 | mAP@50-95 | Thá»i gian Inference | KÃ­ch thÆ°á»›c |
| ------------- | ------------ | ------ | --------- | ------------------- | ---------- |
| PhÃ¡t hiá»‡n Cá»­a | YOLOv11n     | TBD    | TBD       | TBD                 | TBD        |
| Äá»‹nh vá»‹ ID    | YOLOv11-Pose | TBD    | TBD       | TBD                 | TBD        |

---

## HÆ°á»›ng dáº«n PhÃ¡t triá»ƒn

### Phong cÃ¡ch Code

- **PEP 8**: TuÃ¢n thá»§ hÆ°á»›ng dáº«n style Python
- **Black**: Code formatter (Ä‘á»™ dÃ i dÃ²ng: 88)
- **isort**: Sáº¯p xáº¿p import
- **Type hints**: Sá»­ dá»¥ng type annotations khi cÃ³ thá»ƒ

```bash
# Format code
black src/
isort src/

# Kiá»ƒm tra style
flake8 src/
```

### Conventional Commits

Dá»± Ã¡n nÃ y tuÃ¢n theo **Unified Conventional Commits Standard (UCCS)**.

**Äá»‹nh dáº¡ng commit**:
```
<type>(<scope>): <description>

[optional body]
```

**Types**:
- `feat`: TÃ­nh nÄƒng hoáº·c kháº£ nÄƒng má»›i
- `fix`: Sá»­a lá»—i hoáº·c hiá»‡u chá»‰nh
- `refactor`: TÃ¡i cáº¥u trÃºc code khÃ´ng thay Ä‘á»•i hÃ nh vi
- `docs`: Cáº­p nháº­t tÃ i liá»‡u
- `style`: Format code (khÃ´ng thay Ä‘á»•i logic)
- `chore`: TÃ¡c vá»¥ báº£o trÃ¬ (dependencies, configs)

ğŸ“š **HÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§**: [`documentation/general/conventional-commit-guideline.md`](documentation/general/conventional-commit-guideline.md)

### Chiáº¿n lÆ°á»£c Branch

- `main`: Code sáºµn sÃ ng production
- `develop`: Branch tÃ­ch há»£p
- `feature/*`: TÃ­nh nÄƒng má»›i
- `fix/*`: Sá»­a lá»—i
- `experiment/*`: CÃ´ng viá»‡c thá»­ nghiá»‡m

### Quy trÃ¬nh Pull Request

1. Táº¡o feature branch tá»« `develop`
2. Thá»±c hiá»‡n thay Ä‘á»•i vá»›i conventional commits
3. Viáº¿t/cáº­p nháº­t tests
4. Submit PR vá»›i mÃ´ táº£ rÃµ rÃ ng
5. Pass CI checks vÃ  code review
6. Merge vÃ o `develop`

### YÃªu cáº§u Testing

```bash
# Cháº¡y táº¥t cáº£ tests
pytest tests/

# Cháº¡y tests module cá»¥ thá»ƒ
pytest tests/test_detection.py

# Táº¡o bÃ¡o cÃ¡o coverage
pytest --cov=src tests/
```

---

## TÃ i liá»‡u

### TÃ i liá»‡u CÃ³ sáºµn

#### Chung
- [HÆ°á»›ng dáº«n Conventional Commit](documentation/general/conventional-commit-guideline.md)
- [Kiáº¿n trÃºc Há»‡ thá»‘ng](documentation/general/architecture.md) _(Sáº½ táº¡o)_

#### GÃ¡n nhÃ£n Dá»¯ liá»‡u
- [HÆ°á»›ng dáº«n GÃ¡n nhÃ£n Thuá»™c tÃ­nh](documentation/data-labeling/attribute-annotation-guideline.md)
- [HÆ°á»›ng dáº«n GÃ¡n nhÃ£n Cá»­a Container](documentation/data-labeling/container-door-labeling-guideline.md)
- [HÆ°á»›ng dáº«n GÃ¡n nhÃ£n ID Container](documentation/data-labeling/id-container-labeling-guideline.md)

#### Theo Module
- **Module 1 (Detection)**:
  - [PhÆ°Æ¡ng phÃ¡p PhÃ¢n táº§ng Dá»¯ liá»‡u](documentation/modules/module-1-detection/data-splitting-methodology.md)
  - [Äáº·c táº£ Ká»¹ thuáº­t: PhÃ¢n táº§ng Dá»¯ liá»‡u](documentation/modules/module-1-detection/technical-specification-data-splitting.md)
  - [HÆ°á»›ng dáº«n Training](documentation/modules/module-1-detection/training-guide.md) _(Sáº½ táº¡o)_

---

## Lá»™ trÃ¬nh

### Tráº¡ng thÃ¡i Hiá»‡n táº¡i

- âœ… Thu tháº­p vÃ  gÃ¡n nhÃ£n dá»¯ liá»‡u (831 áº£nh)
- âœ… Thiáº¿t láº­p hÆ°á»›ng dáº«n gÃ¡n nhÃ£n dá»¯ liá»‡u
- âœ… Thiáº¿t káº¿ phÆ°Æ¡ng phÃ¡p phÃ¢n táº§ng dá»¯ liá»‡u
- âœ… HoÃ n thÃ nh EDA vÃ  phÃ¢n tÃ­ch dataset
- ğŸŸ¡ Module 1 (Detection) - Äang phÃ¡t triá»ƒn
- ğŸŸ¡ Module 3 (Localization) - Äang phÃ¡t triá»ƒn

### Má»‘c Sáº¯p tá»›i

- [ ] HoÃ n thÃ nh training vÃ  Ä‘Ã¡nh giÃ¡ Module 1
- [ ] HoÃ n thÃ nh training vÃ  Ä‘Ã¡nh giÃ¡ Module 3
- [ ] Triá»ƒn khai Module 2 (ÄÃ¡nh giÃ¡ Cháº¥t lÆ°á»£ng)
- [ ] Triá»ƒn khai Module 4 (Náº¯n chá»‰nh Phá»‘i cáº£nh)
- [ ] Triá»ƒn khai Module 5 (TrÃ­ch xuáº¥t OCR)
- [ ] TÃ­ch há»£p vÃ  testing pipeline end-to-end
- [ ] Tá»‘i Æ°u hiá»‡u nÄƒng vÃ  benchmarking
- [ ] Chuáº©n bá»‹ triá»ƒn khai production
- [ ] TÃ­ch há»£p dá»‹ch vá»¥ backend

### Cáº£i tiáº¿n TÆ°Æ¡ng lai

- Xá»­ lÃ½ video real-time
- PhÃ¡t hiá»‡n nhiá»u container trong má»™t áº£nh
- Triá»ƒn khai mobile (TensorFlow Lite / ONNX)
- Dá»‹ch vá»¥ API vá»›i FastAPI
- Pipeline há»c liÃªn tá»¥c

---

## ÄÃ³ng gÃ³p

### CÃ¡ch ÄÃ³ng gÃ³p

ChÃºng tÃ´i hoan nghÃªnh má»i Ä‘Ã³ng gÃ³p! CÃ¡ch báº¡n cÃ³ thá»ƒ giÃºp Ä‘á»¡:

1. **BÃ¡o cÃ¡o Issues**: Sá»­ dá»¥ng GitHub Issues cho bÃ¡o cÃ¡o lá»—i vÃ  yÃªu cáº§u tÃ­nh nÄƒng
2. **Submit Pull Requests**: TuÃ¢n theo quy trÃ¬nh PR nÃªu trÃªn
3. **Cáº£i thiá»‡n TÃ i liá»‡u**: Sá»­a lá»—i chÃ­nh táº£, thÃªm vÃ­ dá»¥, lÃ m rÃµ giáº£i thÃ­ch
4. **Chia sáº» Ã tÆ°á»Ÿng**: Tháº£o luáº­n cáº£i tiáº¿n trong GitHub Discussions

### LiÃªn há»‡

- **TrÆ°á»Ÿng dá»± Ã¡n**: duyhxm
- **Tá»• chá»©c**: CÃ´ng ty SOWATCO
- **Email**: _(ThÃªm náº¿u cÃ³)_

---

## Giáº¥y phÃ©p & Ghi nháº­n

### Giáº¥y phÃ©p

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c cáº¥p phÃ©p theo **Giáº¥y phÃ©p MIT**. Xem file [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t chi tiáº¿t.

### Ghi nháº­n

- **CÃ´ng ty SOWATCO** cho tÃ i trá»£ dá»± Ã¡n vÃ  chuyÃªn mÃ´n lÄ©nh vá»±c
- **Ultralytics** cho framework YOLOv11
- **DVC Team** cho cÃ´ng cá»¥ quáº£n lÃ½ phiÃªn báº£n dá»¯ liá»‡u
- **Weights & Biases** cho ná»n táº£ng theo dÃµi thá»±c nghiá»‡m
- **CVAT** cho cÃ´ng cá»¥ gÃ¡n nhÃ£n
- Cá»™ng Ä‘á»“ng mÃ£ nguá»“n má»Ÿ cho cÃ¡c thÆ° viá»‡n: OpenCV, PyTorch, Albumentations

### TÃ i liá»‡u Tham kháº£o

- [TÃ i liá»‡u YOLOv11](https://docs.ultralytics.com/)
- [TÃ i liá»‡u DVC](https://dvc.org/doc)
- [TÃ i liá»‡u Weights & Biases](https://docs.wandb.ai/)
- [Äá»‹nh dáº¡ng COCO Dataset](https://cocodataset.org/#format-data)

---

**Made with â¤ï¸ for SOWATCO**

